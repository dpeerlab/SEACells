{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEACells Versions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracemalloc\n",
    "import time\n",
    "import scanpy as sc\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import cupyx\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['Raleway'] not found. Falling back to DejaVu Sans.\n",
      "findfont: Font family ['Lato'] not found. Falling back to DejaVu Sans.\n"
     ]
    }
   ],
   "source": [
    "# from importlib import reload\n",
    "from SEACells.core import SEACells\n",
    "# reload(SEACells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = sc.read(\"/home/aparna/DATA/aparnakumar/50000_cells/mouse_marioni_50k.h5ad\") \n",
    "num_cells = 10000\n",
    "ad = ad[:num_cells]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(ad, num_cells, use_gpu, use_sparse): \n",
    "  ## User defined parameters\n",
    "\n",
    "  ## Core parameters \n",
    "  # number of SEACells\n",
    "  n_SEACells = num_cells // 75\n",
    "  build_kernel_on = 'X_pca' # key in ad.obsm to use for computing metacells\n",
    "                            # This would be replaced by 'X_svd' for ATAC data\n",
    "\n",
    "  ## Additional parameters\n",
    "  n_waypoint_eigs = 10 # Number of eigenvalues to consider when initializing metacells\n",
    "\n",
    "  model = SEACells(ad, \n",
    "                                 use_gpu=use_gpu, \n",
    "                                 use_sparse=use_sparse, \n",
    "                                 build_kernel_on=build_kernel_on, \n",
    "                                 n_SEACells=n_SEACells, \n",
    "                                 n_waypoint_eigs=n_waypoint_eigs,\n",
    "                                 convergence_epsilon = 1e-5)\n",
    "  model.construct_kernel_matrix()\n",
    "  model.initialize_archetypes()\n",
    "\n",
    "  start = time.time()\n",
    "  tracemalloc.start()\n",
    "\n",
    "  model.fit(min_iter=10, max_iter=150)\n",
    "\n",
    "  end = time.time()\n",
    "  tot_time = end - start\n",
    "\n",
    "  mem = tracemalloc.get_traced_memory()\n",
    "  tracemalloc.stop()\n",
    "\n",
    "  assignments = model.get_hard_assignments()\n",
    "  \n",
    "  return assignments, tot_time, mem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_versions(ad):\n",
    "    assignments1, time1, mem1 = (0,0,[0, 0]) #get_data(ad, num_cells = num_cells, use_gpu = False, use_sparse=False)\n",
    "    assignments2, time2, mem2 = (0, 0, [0, 0])#get_data(ad, num_cells = num_cells, use_gpu = False, use_sparse= True)\n",
    "    assignments3, time3, mem3 = get_data(ad, num_cells = num_cells, use_gpu = True, use_sparse=False)\n",
    "    assignments4, time4, mem4 = get_data(ad, num_cells = num_cells, use_gpu = True, use_sparse= True)\n",
    "\n",
    "    # Write the assignments\n",
    "    assignments = [assignments1, assignments2, assignments3, assignments4] \n",
    "    \n",
    "    # Write the time and memory data\n",
    "    comparisons = pd.DataFrame({'version': ['v1: no GPU, no sparse', 'v2:  no GPU, yes sparse', 'v3: yes GPU, no sparse', 'v4: yes GPU, yes sparse'], \n",
    "                           'time (s)': [time1, time2, time3, time4],\n",
    "                           'peak memory': [mem1[1], mem2[1], mem3[1], mem4[1]]})\n",
    "    \n",
    "    return assignments, comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mempool = cp.get_default_memory_pool()\n",
    "# pinned_mempool = cp.get_default_pinned_memory_pool()\n",
    "\n",
    "# print(mempool.used_bytes())              \n",
    "# print(mempool.total_bytes())             \n",
    "# print(pinned_mempool.n_free_blocks())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_cpu = np.ndarray(100, dtype=np.float32)\n",
    "# a = cp.array(a_cpu)\n",
    "# print(a.nbytes)                          # 400\n",
    "# print(mempool.used_bytes())              # 512\n",
    "# print(mempool.total_bytes())             # 512\n",
    "# print(pinned_mempool.n_free_blocks())    # 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3 = cp.random.random((13, 1000))\n",
    "# print(B3.nbytes)                          \n",
    "# print(mempool.used_bytes())              \n",
    "# print(mempool.total_bytes())             \n",
    "# print(pinned_mempool.n_free_blocks())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B3 = cp.sparse.csr_matrix(B3)                        \n",
    "# print(mempool.used_bytes())              \n",
    "# print(mempool.total_bytes())             \n",
    "# print(pinned_mempool.n_free_blocks())    \n",
    "\n",
    "# B3 =B3.argmin(axis=0)\n",
    "# print(B3.nbytes)                          \n",
    "# print(mempool.used_bytes())              \n",
    "# print(mempool.total_bytes())             \n",
    "# print(pinned_mempool.n_free_blocks())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.sparse\n",
    "\n",
    "# ATA = cp.random.random((1000, 1000))\n",
    "# ATA = cp.sparse.csr_matrix(ATA)\n",
    "\n",
    "\n",
    "# f = ((ATA.multiply(ATA)).sum(axis=0)).ravel()\n",
    "# g = ATA.diagonal().ravel()\n",
    "\n",
    "# k =  13\n",
    "# n = 1000\n",
    "# d = cp.sparse.csr_matrix((k, n), dtype=cp.float64)\n",
    "# omega = cp.sparse.csr_matrix((k, n), dtype=cp.float64)\n",
    "\n",
    "# # keep track of selected indices\n",
    "# centers = cp.sparse.csr_matrix((k, n), dtype=cp.float64)\n",
    "\n",
    "# # sampling\n",
    "# for j in tqdm(range(k)):\n",
    "#         score = f / g\n",
    "#         p = score.argmax()\n",
    "        \n",
    "#         delta_term1 = ATA[:, p].toarray().squeeze()\n",
    "#         #     # print(delta_term1)\n",
    "#         ic(omega[:, p].shape)\n",
    "#         ic(type(omega[:, p].reshape(-1, 1).multiply(omega)))\n",
    "#         delta_term2 = omega[:, p].reshape(-1, 1).multiply(omega).sum(axis=0).squeeze()\n",
    "#         delta = delta_term1 - delta_term2\n",
    "\n",
    "#         #     # some weird rounding errors\n",
    "#         # BOOKMARK\n",
    "#         #delta[p] = [0, delta[p]].max()\n",
    "\n",
    "#         #     o = delta / np.max([np.sqrt(delta[p]), 1e-6])\n",
    "#         #     omega_square_norm = np.linalg.norm(o) ** 2\n",
    "#         #     omega_hadamard = np.multiply(o, o)\n",
    "#         #     term1 = omega_square_norm * omega_hadamard\n",
    "\n",
    "#         #     # update f (term2)\n",
    "#         #     pl = np.zeros(n)\n",
    "#         #     for r in range(j):\n",
    "#         #         omega_r = omega[r, :]\n",
    "#         #         pl += np.dot(omega_r, o) * omega_r\n",
    "\n",
    "#         #     ATAo = (ATA @ o.reshape(-1, 1)).ravel()\n",
    "#         #     term2 = np.multiply(o, ATAo - pl)\n",
    "\n",
    "#         #     # update f\n",
    "#         #     f += -2.0 * term2 + term1\n",
    "\n",
    "#         #     # update g\n",
    "#         #     g += omega_hadamard\n",
    "\n",
    "#         #     # store omega and delta\n",
    "#         #     d[j, :] = delta\n",
    "#         #     omega[j, :] = o\n",
    "\n",
    "#         #     # add index\n",
    "#         #     centers[j] = int(p)\n",
    "\n",
    "#         # return centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delta_term1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = cp.array([121])\n",
    "# omega = cp.sparse.csr_matrix((14, 1000), dtype=cp.float64)\n",
    "# thing = omega[:, p].reshape(-1, 1).multiply(omega).sum(axis=0).squeeze()\n",
    "# ic(thing.shape)\n",
    "# ic(type(thing))\n",
    "\n",
    "\n",
    "# type(thing.sum(axis=0))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n = 1000\n",
    "# k = 14\n",
    "\n",
    "# # precompute M.T * M\n",
    "# # ATA = M.T @ M\n",
    "# ATA = cupyx.scipy.sparse.csr_matrix((n, n))\n",
    "\n",
    "\n",
    "# f = cp.array((ATA.multiply(ATA)).sum(axis=0)).ravel()\n",
    "# g = cp.array(ATA.diagonal()).ravel()\n",
    "\n",
    "# d = cp.sparse.csr_matrix((k, n))\n",
    "# omega = cp.sparse.csr_matrix((k, n))\n",
    "\n",
    "# # keep track of selected indices\n",
    "# centers = cp.sparse.csr_matrix((k, n))\n",
    "\n",
    "# # sampling\n",
    "# for j in tqdm(range(k)):\n",
    "#     # Compute score, dividing the sparse f by the sparse g\n",
    "#     score = f / g\n",
    "            \n",
    "#     # Compute p, which is the largest score\n",
    "#     p = cp.argmax(score)\n",
    "\n",
    "#     # Compute delta_term1 to be the column of ATA at index p\n",
    "#     delta_term1 = ATA[:, p].toarray().squeeze()\n",
    "\n",
    "#     # Compute delta_term2 to be the sum of the outer product of omega and itself\n",
    "#     delta_term2 = (omega[:, p].reshape(-1, 1).multiply(omega).sum(axis=0).squeeze())\n",
    "#     delta = delta_term1 - delta_term2\n",
    "\n",
    "#     # some weird rounding errors\n",
    "#     delta[p] = max([0, delta[p]])\n",
    "\n",
    "#     o = delta / max([cp.sqrt(delta[p]), 1e-6])\n",
    "#     omega_square_norm = cp.linalg.norm(o) ** 2\n",
    "#     omega_hadamard = cp.multiply(o, o)\n",
    "#     term1 = omega_square_norm * omega_hadamard\n",
    "\n",
    "#     # update f (term2)\n",
    "#     pl = cp.zeros(n)\n",
    "#     for r in range(j):\n",
    "#         omega_r = omega[r, :]\n",
    "#         pl += omega_r.dot(o) * omega_r\n",
    "\n",
    "#     ATAo = (ATA @ o.reshape(-1, 1)).ravel()\n",
    "#     term2 = o *  (ATAo - pl)\n",
    "\n",
    "#     # update f\n",
    "#     f += -2.0 * term2 + term1\n",
    "\n",
    "#     # update g\n",
    "#     g += omega_hadamard\n",
    "\n",
    "#     # store omega and delta\n",
    "#     d[j, :] = delta\n",
    "#     omega[j, :] = o\n",
    "\n",
    "#     # add index\n",
    "#     centers[j] = int(p)\n",
    "\n",
    "# centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cupy\n",
    "\n",
    "# kernel_matrix =  cupyx.scipy.sparse.rand(1000, 1000, density=0.01, format='csr', dtype=np.float64)\n",
    "# # Make a sparse csr matrix of random data \n",
    "# reconstruction = cupyx.scipy.sparse.rand(1000, 1000, density=0.01, format='csr', dtype=np.float64)\n",
    "\n",
    "# ic(type(kernel_matrix))\n",
    "# ic(type(reconstruction))\n",
    "\n",
    "\n",
    "\n",
    "# cp.linalg.norm(kernel_matrix - reconstruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assignments4, time4, mem4 = get_data(ad, num_cells = num_cells, use_gpu = True, use_sparse= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOT SPARSE AND GPU\n",
      "TRYING SEACellsGPUDense\n",
      "Welcome to SEACells GPU!\n",
      "Computing kNN graph using scanpy NN ...\n",
      "Computing radius for adaptive bandwidth kernel...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0045511722564697266,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0863da9928c2425597f1a62b4ac1a9b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making graph symmetric...\n",
      "Parameter graph_construction = union being used to build KNN graph...\n",
      "Computing RBF kernel...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0042877197265625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "309e25a9746048aba4e943ec08812cf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building similarity LIL matrix...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003313302993774414,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a424b1b9efe74ec0a97159e036dbd679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing CSR matrix...\n",
      "Building kernel on X_pca\n",
      "Computing diffusion components from X_pca for waypoint initialization ... \n",
      "Determing nearest neighbor graph...\n",
      "Done.\n",
      "Sampling waypoints ...\n",
      "Done.\n",
      "Selecting 118 cells from waypoint initialization.\n",
      "Initializing residual matrix using greedy column selection\n",
      "Initializing f and g...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [00:00<00:00, 149.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 15 cells from greedy initialization.\n",
      "Randomly initialized A matrix.\n",
      "Setting convergence threshold at 0.00178\n",
      "Starting iteration 1.\n",
      "Completed iteration 1.\n",
      "Starting iteration 10.\n",
      "Completed iteration 10.\n",
      "Starting iteration 20.\n",
      "Completed iteration 20.\n",
      "Starting iteration 30.\n",
      "Completed iteration 30.\n",
      "Starting iteration 40.\n",
      "Completed iteration 40.\n",
      "Converged after 46 iterations.\n",
      "SPARSE AND GPU\n",
      "TRYING SEACellsGPU\n",
      "Welcome to SEACells GPU!\n",
      "build_graph.SEACellGraph completed\n",
      "Computing kNN graph using scanpy NN ...\n",
      "Computing radius for adaptive bandwidth kernel...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0035085678100585938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "137b6a50e23e4e30865e03d2e1ccedb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making graph symmetric...\n",
      "Parameter graph_construction = union being used to build KNN graph...\n",
      "Computing RBF kernel...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003983259201049805,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50b9c66ae6949c7aa3251e61765786d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building similarity LIL matrix...\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.003713846206665039,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10000,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6785fcfa015a40d78beef8ffb4f20055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing CSR matrix...\n",
      "Building kernel on X_pca\n",
      "Computing diffusion components from X_pca for waypoint initialization ... \n",
      "Determing nearest neighbor graph...\n",
      "Done.\n",
      "Sampling waypoints ...\n",
      "Done.\n",
      "Selecting 118 cells from waypoint initialization.\n",
      "Initializing residual matrix using greedy column selection\n",
      "Initializing f and g...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/25 [00:00<?, ?it/s]/home/aparna/miniconda3/lib/python3.9/site-packages/cupyx/scipy/sparse/_compressed.py:545: SparseEfficiencyWarning: Changing the sparsity structure of a csr_matrix is expensive.\n",
      "  warnings.warn('Changing the sparsity structure of a '\n",
      "100%|██████████| 25/25 [00:00<00:00, 48.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting 15 cells from greedy initialization.\n",
      "Randomly initialized A matrix.\n",
      "Convergence threshold set to 0.0017774726787632225 based on epsilon = 1e-05\n",
      "Starting iteration 1.\n",
      "Completed iteration 1.\n",
      "Starting iteration 10.\n",
      "Completed iteration 10.\n",
      "Starting iteration 20.\n",
      "Completed iteration 20.\n",
      "Starting iteration 30.\n",
      "Completed iteration 30.\n",
      "Converged after 36 iterations.\n"
     ]
    }
   ],
   "source": [
    "assignments, comparisons = all_versions(ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>version</th>\n",
       "      <th>time (s)</th>\n",
       "      <th>peak memory</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v1: no GPU, no sparse</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v2:  no GPU, yes sparse</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v3: yes GPU, no sparse</td>\n",
       "      <td>110.173131</td>\n",
       "      <td>2465051725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v4: yes GPU, yes sparse</td>\n",
       "      <td>84.051319</td>\n",
       "      <td>17540950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   version    time (s)  peak memory\n",
       "0    v1: no GPU, no sparse    0.000000            0\n",
       "1  v2:  no GPU, yes sparse    0.000000            0\n",
       "2   v3: yes GPU, no sparse  110.173131   2465051725\n",
       "3  v4: yes GPU, yes sparse   84.051319     17540950"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display comparisons \n",
    "comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparisons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Core parameters \n",
    "# # number of SEACells\n",
    "# n_SEACells = num_cells // 75\n",
    "# build_kernel_on = 'X_pca' # key in ad.obsm to use for computing metacells\n",
    "#                             # This would be replaced by 'X_svd' for ATAC data\n",
    "\n",
    "# ## Additional parameters\n",
    "# n_waypoint_eigs = 10\n",
    "  \n",
    "# # Initialize\n",
    "# model1 = SEACells(ad, use_gpu=False, use_sparse=False, build_kernel_on=build_kernel_on, n_SEACells=n_SEACells, n_waypoint_eigs=n_waypoint_eigs, convergence_epsilon = 1e-5)\n",
    "# model4 = SEACells(ad, use_gpu=True, use_sparse=True, build_kernel_on=build_kernel_on, n_SEACells=n_SEACells, n_waypoint_eigs=n_waypoint_eigs, convergence_epsilon = 1e-5)\n",
    "# model3 = SEACells(ad, use_gpu=True, use_sparse=False, build_kernel_on=build_kernel_on, n_SEACells=n_SEACells, n_waypoint_eigs=n_waypoint_eigs, convergence_epsilon = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.construct_kernel_matrix() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K= model1.K \n",
    "# kernel_matrix = model1.kernel_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.sparse\n",
    "# model3.K = model1.K\n",
    "# # convert model1.K to the right type (cupyx.scipy.sparse._csr.csr_matrix) \n",
    "# model4.K = cupyx.scipy.sparse.csr_matrix(model1.K)\n",
    "\n",
    "# ic(type(model1.K))\n",
    "# ic(type(model3.K)) \n",
    "# ic(type(model4.K)) \n",
    "\n",
    "# ic(model1.K.shape)\n",
    "# ic(model3.K.shape)\n",
    "# ic(model4.K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy\n",
    "\n",
    "# model3.kernel_matrix = model1.kernel_matrix \n",
    "# model4.kernel_matrix = cupyx.scipy.sparse.csr_matrix(model1.kernel_matrix)\n",
    "\n",
    "\n",
    "# ic(type(model1.kernel_matrix))\n",
    "# ic(type(model3.kernel_matrix)) \n",
    "# ic(type(model4.kernel_matrix)) \n",
    "\n",
    "# ic(model1.kernel_matrix.shape)\n",
    "# ic(model3.kernel_matrix.shape)\n",
    "# ic(model4.kernel_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.initialize_archetypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3.archetypes = model1.archetypes \n",
    "# model4.archetypes = cp.array(model1.archetypes)\n",
    "\n",
    "# ic(model1.archetypes.shape)\n",
    "# ic(model3.archetypes.shape)\n",
    "# ic(model4.archetypes.shape)\n",
    "\n",
    "# ic(type(model1.archetypes))\n",
    "# ic(type(model3.archetypes))\n",
    "# ic(type(model4.archetypes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.initialize()\n",
    "# ic(model1.archetypes.shape) \n",
    "# ic(type(model1.archetypes)) \n",
    "\n",
    "# ic(model1.k)\n",
    "# ic(type(model1.k))\n",
    "\n",
    "# ic(model1.B0.shape)\n",
    "# ic(type(model1.B0))\n",
    "\n",
    "# ic(model1.A0.shape)\n",
    "# ic(type(model1.A0))\n",
    "\n",
    "# ic(model1.A_.shape)\n",
    "# ic(type(model1.A_)) \n",
    "\n",
    "# ic(model1.B_.shape)\n",
    "# ic(type(model1.B_))\n",
    "\n",
    "# ic(model1.convergence_threshold)\n",
    "# ic(type(model1.convergence_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3.initialize()\n",
    "# ic(model3.archetypes.shape)\n",
    "# ic(type(model3.archetypes))\n",
    "\n",
    "# ic(model3.k)\n",
    "# ic(type(model3.k))\n",
    "\n",
    "# ic(model3.B0.shape)\n",
    "# ic(type(model3.B0))\n",
    "\n",
    "# ic(model3.A0.shape)\n",
    "# ic(type(model3.A0))\n",
    "\n",
    "# ic(model3.A_.shape)\n",
    "# ic(type(model3.A_))\n",
    "\n",
    "# ic(model3.B_.shape)\n",
    "# ic(type(model3.B_))\n",
    "\n",
    "# ic(model3.convergence_threshold)\n",
    "# ic(type(model3.convergence_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = len(model4.archetypes)\n",
    "# cols = cp.arange(k)\n",
    "# rows = model4.archetypes\n",
    "# shape = (n, k) \n",
    "# data = cp.ones(len(rows))\n",
    "# B0 = cupyx.scipy.sparse.csr_matrix((cp.ones(len(rows)), (rows, cols)), shape=shape)\n",
    "# B = B0.copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model4.initialize() \n",
    "# ic(model4.archetypes.shape)\n",
    "# ic(type(model4.archetypes))\n",
    "\n",
    "# ic(model4.k)\n",
    "# ic(type(model4.k))\n",
    "\n",
    "# ic(model4.B0.shape)\n",
    "# ic(type(model4.B0))\n",
    "\n",
    "# ic(model4.A0.shape)\n",
    "# ic(type(model4.A0))\n",
    "\n",
    "# ic(model4.A_.shape)\n",
    "# ic(type(model4.A_))\n",
    "\n",
    "# ic(model4.B_.shape)\n",
    "# ic(type(model4.B_))\n",
    "\n",
    "# ic(model4.convergence_threshold)\n",
    "# ic(type(model4.convergence_threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = model4.k\n",
    "# cols = cp.arange(k)\n",
    "# rows = model4.archetypes\n",
    "# shape = (n, k)\n",
    "# B0 = cupyx.scipy.sparse.csr_matrix((cp.ones(len(rows)), (rows, cols)), shape=shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# archetypes_per_cell = int(k * 0.25)\n",
    "# rows = np.random.randint(0, k, size=(n, archetypes_per_cell)).reshape(-1)\n",
    "# columns = np.repeat(np.arange(n), archetypes_per_cell)\n",
    "\n",
    "# ic(rows.shape)\n",
    "# ic(columns.shape)\n",
    "# ic(k, n)\n",
    "\n",
    "# A0 = scipy.sparse.csr_matrix((np.random.random(len(rows)), (rows, columns)), shape=(k, n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# archetypes_per_cell = int(k * 0.25)\n",
    "# rows = np.random.randint(0, k, size=(n, archetypes_per_cell)).reshape(-1)\n",
    "# columns = np.repeat(np.arange(n), archetypes_per_cell)\n",
    "#             # print(type(rows))\n",
    "#             # print(type(columns))\n",
    "\n",
    "# A0 = scipy.sparse.csr_matrix((np.random.random(len(rows)), (rows, columns)), shape=(k, n))\n",
    "#             # print(type(A0))\n",
    "#             # print(\"STARTING NORMALIZE\")\n",
    "# A0 = cupyx.scipy.sparse.csr_matrix(normalize(A0, axis=0, norm=\"l1\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Now we need to compare \n",
    "\n",
    "# ic(np.allclose(model1.archetypes, model3.archetypes))\n",
    "# ic(np.allclose(model1.archetypes, model4.archetypes))\n",
    "\n",
    "# ic(np.allclose(model1.k, model3.k))\n",
    "# ic(np.allclose(model1.k, model4.k))\n",
    "\n",
    "# ic(np.allclose(model1.B0, model3.B0))\n",
    "# ic(np.allclose(model1.B0, model4.B0.get().todense()))\n",
    "\n",
    "# ic(np.allclose(model1.A0, model3.A0))\n",
    "# ic(np.allclose(model1.A0, model4.A0.get().todense()))\n",
    "\n",
    "# ic(np.allclose(model1.A_, model3.A_))\n",
    "# ic(np.allclose(model1.A_, model4.A_.get().todense()))\n",
    "\n",
    "# ic(np.allclose(model1.B_, model3.B_))\n",
    "# ic(np.allclose(model1.B_, model4.B_.get().todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Compare the A's of model 3 and model 4 \n",
    "# ic(np.allclose(model3.A0, model4.A0.get().todense()))\n",
    "# ic(np.allclose(model3.A_, model4.A_.get().todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set A0 of model 3 and model 4 to be the same as model 1 \n",
    "# model3.A0 = model1.A0 \n",
    "# model4.A0 = cupyx.scipy.sparse.csr_matrix(cp.array(model1.A0))\n",
    "\n",
    "# # check is close \n",
    "# ic(np.allclose(model1.A0, model3.A0)) \n",
    "# ic(np.allclose(model1.A0, model4.A0.get().todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model3.A_ = model3._updateA(model3.B0, model3.A0)\n",
    "# model4.A_ = model4._updateA(model4.B0, model4.A0)\n",
    "\n",
    "# # Check is close \n",
    "# ic(np.allclose(model1.A_, model3.A_)) \n",
    "# ic(np.allclose(model1.A_, model4.A_.get().todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Double check on B_ \n",
    "\n",
    "# ic(np.allclose(model1.B_, model3.B_)) \n",
    "# ic(np.allclose(model1.B_, model4.B_.get().todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSS3 = model3.compute_RSS(model3.A_, model3.B_)\n",
    "# RSS4 = model4.compute_RSS(model4.A_, model4.B_)\n",
    "# RSS1 = model1.compute_RSS(model1.A_, model1.B_)\n",
    "\n",
    "# ic(type(RSS1)) \n",
    "# ic(type(RSS3)) \n",
    "# ic(type(RSS4)) \n",
    "\n",
    "# ic(RSS1.shape) \n",
    "# ic(RSS3.shape) \n",
    "# ic(RSS4.shape)\n",
    "\n",
    "# ic(np.allclose(RSS1, RSS3)) \n",
    "# ic(np.allclose(RSS1, RSS4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.sparse\n",
    "\n",
    "# reconstruction1 = model1.compute_reconstruction(model1.A_, model1.B_)\n",
    "# reconstruction4 = model4.compute_reconstruction(cupyx.scipy.sparse.csr_matrix(cp.array(model1.A_)), cupyx.scipy.sparse.csr_matrix(cp.array(model1.B_)))\n",
    "# reconstruction3 = model3.compute_reconstruction(model3.A_, model3.B_)\n",
    "\n",
    "# ic(type(reconstruction1)) \n",
    "# ic(type(reconstruction3))\n",
    "# ic(type(reconstruction4)) \n",
    "\n",
    "# ic(reconstruction1.shape) \n",
    "# ic(reconstruction3.shape)\n",
    "# ic(reconstruction4.shape)\n",
    "\n",
    "# ic(np.allclose(reconstruction1, reconstruction3))\n",
    "# ic(np.allclose(reconstruction1, reconstruction4.get().todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.sparse\n",
    "\n",
    "# diff1 = model1.kernel_matrix - reconstruction1 \n",
    "# diff3 = model3.kernel_matrix - reconstruction3\n",
    "# ic(type(model1.kernel_matrix) )\n",
    "\n",
    "\n",
    "# diff4 = cupyx.scipy.sparse.csr_matrix(model1.kernel_matrix) - reconstruction4 \n",
    "\n",
    "# ic(type(diff1)) \n",
    "# ic(type(diff3))\n",
    "# ic(type(diff4)) \n",
    "\n",
    "# ic(diff1.shape) \n",
    "# ic(diff3.shape )\n",
    "# ic(diff4.shape) \n",
    "\n",
    "# ic(np.allclose(diff1, diff3))\n",
    "# ic(np.allclose(diff1, diff4.get().todense()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # take the norm of the difference \n",
    "# import scipy.sparse.linalg\n",
    "# from scipy.sparse.linalg import norm\n",
    "\n",
    "\n",
    "# norm1 = np.linalg.norm(diff1) \n",
    "# norm3 = np.linalg.norm(diff3)\n",
    "# norm4 = np.linalg.norm(diff4.get().todense())\n",
    "# norm4 = norm(diff4.get())\n",
    "\n",
    "# ic(type(norm1)) \n",
    "# ic(type(norm3)) \n",
    "# ic(type(norm4)) \n",
    "\n",
    "# ic(norm1)\n",
    "# ic(norm3)\n",
    "# ic(norm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check A and B \n",
    "# ic(model1.A_.shape)\n",
    "# ic(model3.A_.shape)\n",
    "# ic(model4.A_.shape)\n",
    "\n",
    "# ic(model1.B_.shape)\n",
    "# ic(model3.B_.shape)\n",
    "# ic(model4.B_.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _updateA(self, B, A_prev):\n",
    "#         \"\"\"Compute assignment matrix A using constrained gradient descent via Frank-Wolfe algorithm.\n",
    "\n",
    "#         Given archetype matrix B and using kernel matrix K, compute assignment matrix A using constrained gradient\n",
    "#         descent via Frank-Wolfe algorithm.\n",
    "\n",
    "#         :param B: (n x k csr_matrix) defining SEACells as weighted combinations of cells\n",
    "#         :param A_prev: (n x k csr_matrix) defining previous weights used for assigning cells to SEACells\n",
    "#         :return: (n x k csr_matrix) defining updated weights used for assigning cells to SEACells\n",
    "#         \"\"\"\n",
    "#         ic(\"updateA\")\n",
    "#         n, k = B.shape\n",
    "#         A = A_prev\n",
    "#         # ic(type(A))\n",
    "\n",
    "#         t = 0  # current iteration (determine multiplicative update)\n",
    "\n",
    "#         # print(\"bookmark\")\n",
    "#         Ag = A\n",
    "#         # ic(type(Ag))\n",
    "#         Bg = B\n",
    "#         # print(type(self.K))\n",
    "#         Kg = self.K\n",
    "#         # ic(type(Bg))\n",
    "#         # ic(type(Kg))\n",
    "#         # ic(\"computed Ag, Bg, Kg\")\n",
    "\n",
    "#         # precompute some gradient terms\n",
    "#         t2g = Kg.dot(Bg).T\n",
    "#         t1g = t2g.dot(Bg)\n",
    "#         # ic(\"computed t2g, t1g\")\n",
    "#         # ic(type(t2g), type(t1g))\n",
    "\n",
    "#         # update rows of A for given number of iterations\n",
    "#         while t < self.max_FW_iter:\n",
    "#             # compute gradient (must convert matrix to ndarray)\n",
    "#             # X = t1g.dot(Ag)\n",
    "#             # print(X.shape)\n",
    "#             # print(type(X))\n",
    "#             # print(t2g.shape)\n",
    "#             # print(type(t2g))\n",
    "#             # Y = X - t2g \n",
    "#             # print(Y.shape)\n",
    "#             # print(type(Y))\n",
    "#             # Z = 2.0 *Y \n",
    "#             # print(Z.shape)\n",
    "#             # print(type(Z))\n",
    "#             # print((cp.subtract(t1g.dot(Ag), t2g)).shape)\n",
    "#             # print((cp.multiply(2, cp.subtract(t1g.dot(Ag), t2g))).shape)\n",
    "#             Gg = 2.0*(t1g.dot(Ag) - t2g)\n",
    "#             # ic(Gg.shape)\n",
    "#             # ic(type(Gg))\n",
    "#             # get argmins\n",
    "#             amins = Gg.argmin(axis = 0)\n",
    "#             # ic(amins.shape)\n",
    "#             # ic(type(amins))\n",
    "#             # loop free implementaton\n",
    "#             eg = cupyx.scipy.sparse.csr_matrix((k, n), dtype=cp.float64)\n",
    "#             ic(type(eg))\n",
    "#             eg[amins, cp.arange(n)] = 1.0\n",
    "#             ic(type(eg))\n",
    "#             # print(\"eg\")\n",
    "\n",
    "#             f = 2.0 / (t + 2.0)\n",
    "#             ic(type(f))\n",
    "#             Ag = Ag + (f * (eg - Ag))\n",
    "#             # Ag = cp.add(Ag, cp.multiply(f, cp.subtract(eg, Ag)))\n",
    "#             t += 1\n",
    "#             # print(\"f, Ag, t\")\n",
    "\n",
    "\n",
    "#         # A = Ag.get()\n",
    "#         A = Ag\n",
    "\n",
    "\n",
    "#         del t1g, t2g, Ag, Kg, Gg, Bg, eg, amins\n",
    "#         cp._default_memory_pool.free_all_blocks()\n",
    "\n",
    "#         # ic(type(A))\n",
    "#         return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _updateA(model4, model4.B_, model4.A_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A1 = model1._updateA(model1.B_, model1.A_)\n",
    "# A3 = model3._updateA(model3.B_, model3.A_)\n",
    "# A4 = model4._updateA(model4.B_, model4.A_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1._updateB(A1, model1.B_)\n",
    "# model3._updateB(A3, model3.B_)\n",
    "# model4._updateB(A4, model4.B_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model1.step()\n",
    "# model3.step()\n",
    "# model4.step()\n",
    "\n",
    "# model4._updateA(model4.B_, model4.A_) \n",
    "# # model4._updateB(model4.A_, model4.B_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# B = model4.B_ \n",
    "# A_prev = model4.A_ \n",
    "\n",
    "# n, k = B.shape\n",
    "# # print(n, k)\n",
    "# A = A_prev\n",
    "# # ic(type(A))\n",
    "\n",
    "# t = 0  # current iteration (determine multiplicative update)\n",
    "\n",
    "# # print(\"bookmark\")\n",
    "# Ag = A\n",
    "# # ic(type(A))\n",
    "# Bg = B\n",
    "\n",
    "# ic(type(model4.K))\n",
    "# Kg = model4.K"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
